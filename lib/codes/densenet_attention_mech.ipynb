{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 30 classes.\n",
      "Found 2000 images belonging to 30 classes.\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NAMITHAA\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2488 - loss: 2.8286\n",
      "Epoch 1: val_accuracy improved from -inf to 0.75302, saving model to C:/Users/NAMITHAA/Downloads/save_models.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1052s\u001b[0m 4s/step - accuracy: 0.2495 - loss: 2.8260 - val_accuracy: 0.7530 - val_loss: 1.0695 - learning_rate: 1.0000e-04\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_accuracy improved from 0.75302 to 0.81250, saving model to C:/Users/NAMITHAA/Downloads/save_models.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8125 - val_loss: 0.9862 - learning_rate: 1.0000e-04\n",
      "Epoch 3/40\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7473 - loss: 0.9822\n",
      "Epoch 3: val_accuracy improved from 0.81250 to 0.86038, saving model to C:/Users/NAMITHAA/Downloads/save_models.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 2s/step - accuracy: 0.7474 - loss: 0.9816 - val_accuracy: 0.8604 - val_loss: 0.5466 - learning_rate: 1.0000e-04\n",
      "Epoch 4/40\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.86038\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8125 - val_loss: 0.8317 - learning_rate: 1.0000e-04\n",
      "Epoch 5/40\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8416 - loss: 0.5836\n",
      "Epoch 5: val_accuracy improved from 0.86038 to 0.89062, saving model to C:/Users/NAMITHAA/Downloads/save_models.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 2s/step - accuracy: 0.8417 - loss: 0.5835 - val_accuracy: 0.8906 - val_loss: 0.4093 - learning_rate: 1.0000e-04\n",
      "Epoch 6/40\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.89062 to 0.93750, saving model to C:/Users/NAMITHAA/Downloads/save_models.keras\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9375 - val_loss: 0.2725 - learning_rate: 1.0000e-04\n",
      "Epoch 7/40\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8792 - loss: 0.4368\n",
      "Epoch 7: val_accuracy did not improve from 0.93750\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 2s/step - accuracy: 0.8792 - loss: 0.4368 - val_accuracy: 0.8942 - val_loss: 0.3615 - learning_rate: 1.0000e-04\n",
      "Epoch 8/40\n",
      "\n",
      "Epoch 8: val_accuracy improved from 0.93750 to 1.00000, saving model to C:/Users/NAMITHAA/Downloads/save_models.keras\n",
      "\n",
      "Epoch 8: Validation accuracy reached 100.00%, stopping training.\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 224ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0786 - learning_rate: 1.0000e-04\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.8950 - loss: 0.3641\n",
      "Test accuracy: 89.52%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Custom callback to stop training when validation accuracy reaches 100%\n",
    "class EarlyStoppingAtAccuracy(Callback):\n",
    "    def __init__(self, monitor='val_accuracy', value=1.0, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(f'Early stopping requires {self.monitor} available!', RuntimeWarning)\n",
    "\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(f'\\nEpoch {epoch + 1}: Validation accuracy reached {self.value * 100:.2f}%, stopping training.')\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# Define SE Block\n",
    "class SEBlock(Layer):\n",
    "    def __init__(self, reduction=16, **kwargs):\n",
    "        super(SEBlock, self).__init__(**kwargs)\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "        self.channels = input_shape[-1]\n",
    "        self.global_avg_pool = GlobalAveragePooling2D()\n",
    "        self.dense1 = Dense(self.channels // self.reduction, activation='relu', kernel_initializer='he_normal', use_bias=False)\n",
    "        self.dense2 = Dense(self.channels, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)\n",
    "        super(SEBlock, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        se = self.global_avg_pool(inputs)\n",
    "        se = tf.expand_dims(tf.expand_dims(se, 1), 1)\n",
    "        se = self.dense1(se)\n",
    "        se = self.dense2(se)\n",
    "        return inputs * se\n",
    "\n",
    "# Set dataset directory and parameters\n",
    "dataset_dir = \"C:/Users/NAMITHAA/Downloads/archive/AID\"\n",
    "target_size = (224, 224)  # Target size for DenseNet121\n",
    "batch_size = 32\n",
    "\n",
    "# Define the data generators with increased augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=45,  # Increased rotation range\n",
    "    width_shift_range=0.2,  # Match width shift\n",
    "    height_shift_range=0.2,  # Match height shift\n",
    "    shear_range=0.2,  # Match shear range\n",
    "    zoom_range=0.2,  # Match zoom range\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # Use 20% of the data for validation\n",
    ")\n",
    "\n",
    "# Data generators for training and validation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Set as training data\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Set as validation data\n",
    ")\n",
    "\n",
    "# Load DenseNet121 with pre-trained ImageNet weights\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers on top of DenseNet121\n",
    "x = base_model.output\n",
    "x = SEBlock()(x)  # Insert SE block\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)  # Match number of units\n",
    "x = Dropout(0.3)(x)  # Match dropout rate\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Fine-tune more layers of DenseNet121\n",
    "for layer in base_model.layers[:-50]:\n",
    "    layer.trainable = False  # Match number of frozen layers\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the model with a lower learning rate and learning rate scheduler\n",
    "optimizer = Adam(learning_rate=0.0001)  # Using Adam optimizer\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "filepath = \"C:/Users/NAMITHAA/Downloads/save_models.keras\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=0.000001, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "# Add custom callback to stop training when validation accuracy reaches 100%\n",
    "early_stopping_accuracy = EarlyStoppingAtAccuracy(monitor='val_accuracy', value=1.0, verbose=1)\n",
    "\n",
    "# Train the model with more epochs\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=40,  # Match the number of epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr, early_stopping_accuracy],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)\n",
    "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
